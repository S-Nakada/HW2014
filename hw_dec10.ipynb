{
 "metadata": {
  "name": "",
  "signature": "sha256:b15441d26bbc7e5a5a2c28a817f71cf978d25b49a174fb4d4b204b5667169a92"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from quantecon import MarkovChain\n",
      "from __future__ import division"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "MDP class file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MDP:\n",
      "    \n",
      "    def __init__(self, r, delta, Q):\n",
      "        self.r=np.array(r)\n",
      "        self.delta=delta\n",
      "        self.Q=np.array(Q)\n",
      "        self.n=self.r.shape[0] # number of states\n",
      "        self.m=self.r.shape[1] # number of actions\n",
      "        \n",
      "    def Bellman_Operator(self, w):\n",
      "        w=np.array(w)\n",
      "        objf=self.r+self.delta*self.Q.dot(w)\n",
      "        Bw=np.max(objf, axis=1)\n",
      "        policy=np.argmax(objf, axis=1)\n",
      "        return Bw,policy\n",
      "    \n",
      "    def solve_bellman_equation(self,w0, tol, max_iter):\n",
      "        # Iteration to obtain value function and optimal policy\n",
      "        w_current=np.array(w0)\n",
      "        for t in range(max_iter+1):\n",
      "            w_next, policy=self.Bellman_Operator(w_current)\n",
      "            if np.max(abs(w_current-w_next))<tol:\n",
      "                break\n",
      "            w_current=w_next\n",
      "\n",
      "        # Obtain transition matrix given optimal policy\n",
      "        P=np.zeros((self.n, self.n))\n",
      "        for i in range(self.n):\n",
      "            for j in range(self.n):\n",
      "                P[i,j]=self.Q[i, policy[i], j]\n",
      "        return  w_current, policy, P      \n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Study example in section 5.1: Kurtz' optimal decision"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Parameters\n",
      "beta = 0.5\n",
      "delta = 0.9\n",
      "B = 10\n",
      "M = 5\n",
      "\n",
      "# Period utility function\n",
      "r = np.zeros((B+M+1, M+1))\n",
      "for s in range(B+M+1):\n",
      "    for a in range(M+1):\n",
      "        if a <= min(s, M):\n",
      "            r[s, a] = (s - a) ** beta\n",
      "        else: \n",
      "            r[s, a] = -np.inf\n",
      "        \n",
      "# Transition matrix \n",
      "Q = np.zeros((B+M+1, M+1, B+M+1))\n",
      "for s in range(B+M+1):\n",
      "    for a in range(M+1):\n",
      "        for t in range(B+M+1):\n",
      "            if a <= t <= a+B:    \n",
      "               Q[s, a, t] = 1 / (B + 1)  \n",
      "            else:\n",
      "               Q[s, a, t] = 0\n",
      "\n",
      "print(r)\n",
      "print(Q)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.                -inf        -inf        -inf        -inf        -inf]\n",
        " [ 1.          0.                -inf        -inf        -inf        -inf]\n",
        " [ 1.41421356  1.          0.                -inf        -inf        -inf]\n",
        " [ 1.73205081  1.41421356  1.          0.                -inf        -inf]\n",
        " [ 2.          1.73205081  1.41421356  1.          0.                -inf]\n",
        " [ 2.23606798  2.          1.73205081  1.41421356  1.          0.        ]\n",
        " [ 2.44948974  2.23606798  2.          1.73205081  1.41421356  1.        ]\n",
        " [ 2.64575131  2.44948974  2.23606798  2.          1.73205081  1.41421356]\n",
        " [ 2.82842712  2.64575131  2.44948974  2.23606798  2.          1.73205081]\n",
        " [ 3.          2.82842712  2.64575131  2.44948974  2.23606798  2.        ]\n",
        " [ 3.16227766  3.          2.82842712  2.64575131  2.44948974  2.23606798]\n",
        " [ 3.31662479  3.16227766  3.          2.82842712  2.64575131  2.44948974]\n",
        " [ 3.46410162  3.31662479  3.16227766  3.          2.82842712  2.64575131]\n",
        " [ 3.60555128  3.46410162  3.31662479  3.16227766  3.          2.82842712]\n",
        " [ 3.74165739  3.60555128  3.46410162  3.31662479  3.16227766  3.        ]\n",
        " [ 3.87298335  3.74165739  3.60555128  3.46410162  3.31662479  3.16227766]]\n",
        "[[[ 0.09090909  0.09090909  0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.09090909  0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.          0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.          0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.09090909  0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.09090909\n",
        "    0.09090909]]\n",
        "\n",
        " [[ 0.09090909  0.09090909  0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.09090909  0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.          0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.          0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.09090909  0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.09090909\n",
        "    0.09090909]]\n",
        "\n",
        " [[ 0.09090909  0.09090909  0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.09090909  0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.          0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.          0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.09090909  0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.09090909\n",
        "    0.09090909]]\n",
        "\n",
        " ..., \n",
        " [[ 0.09090909  0.09090909  0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.09090909  0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.          0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.          0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.09090909  0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.09090909\n",
        "    0.09090909]]\n",
        "\n",
        " [[ 0.09090909  0.09090909  0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.09090909  0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.          0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.          0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.09090909  0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.09090909\n",
        "    0.09090909]]\n",
        "\n",
        " [[ 0.09090909  0.09090909  0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.09090909  0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.          0.09090909 ...,  0.          0.          0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.          0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.09090909  0.        ]\n",
        "  [ 0.          0.          0.         ...,  0.09090909  0.09090909\n",
        "    0.09090909]]]\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Apply Bellman operator"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kurtzbellman = MDP(r, delta, Q)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "value_function, policy, P = kurtzbellman.solve_bellman_equation(np.zeros(B+M+1), tol=1e-10, max_iter=10000)\n",
      "\n",
      "print(value_function)\n",
      "print (policy)\n",
      "print (P)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 19.01740222  20.01740222  20.43161578  20.74945302  21.04078099\n",
        "  21.30873018  21.54479816  21.76928181  21.98270358  22.18824323\n",
        "  22.3845048   22.57807736  22.76109127  22.94376708  23.11533996\n",
        "  23.27761762]\n",
        "[0 0 0 0 1 1 1 2 2 3 3 4 5 5 5 5]\n",
        "[[ 0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.          0.\n",
        "   0.          0.          0.        ]\n",
        " [ 0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.          0.\n",
        "   0.          0.          0.        ]\n",
        " [ 0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.          0.\n",
        "   0.          0.          0.        ]\n",
        " [ 0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.          0.\n",
        "   0.          0.          0.        ]\n",
        " [ 0.          0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.          0.          0.          0.        ]\n",
        " [ 0.          0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.          0.          0.          0.        ]\n",
        " [ 0.          0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.          0.          0.          0.        ]\n",
        " [ 0.          0.          0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.          0.          0.        ]\n",
        " [ 0.          0.          0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.          0.          0.        ]\n",
        " [ 0.          0.          0.          0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.          0.        ]\n",
        " [ 0.          0.          0.          0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.          0.        ]\n",
        " [ 0.          0.          0.          0.          0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.        ]\n",
        " [ 0.          0.          0.          0.          0.          0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909]\n",
        " [ 0.          0.          0.          0.          0.          0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909]\n",
        " [ 0.          0.          0.          0.          0.          0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909]\n",
        " [ 0.          0.          0.          0.          0.          0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909  0.09090909  0.09090909\n",
        "   0.09090909  0.09090909  0.09090909  0.09090909]]\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "MDP policy iteration class file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class MDP_pol_iter:\n",
      "    \n",
      "    def __init__(self, r, delta, Q):\n",
      "        self.r=np.array(r)\n",
      "        self.delta=delta\n",
      "        self.Q=np.array(Q)\n",
      "        self.n=self.r.shape[0] # number of states\n",
      "        self.m=self.r.shape[1] # number of actions\n",
      "    \n",
      "    \n",
      "    def value_of_policy(self, policy):\n",
      "        \n",
      "    # Obtain transition matrix given policy\n",
      "        P_pol=np.zeros((self.n, self.n))\n",
      "        policy=np.array(policy)\n",
      "        for i in range(self.n):\n",
      "            for j in range(self.n):\n",
      "                P_pol[i,j]=self.Q[i, policy[i], j]\n",
      "    \n",
      "    # Expected utility by following given policy\n",
      "        \n",
      "        ex_r=np.dot(P_pol,self.r)\n",
      "        discount=1\n",
      "    \n",
      "    # Sum of discounted expected payoff  given policy\n",
      "        v_pol=np.zeros(ex_r.shape)\n",
      "        for t in range(50):\n",
      "            v_pol=v_pol+discount*ex_r\n",
      "            ex_r=np.dot(P_pol, ex_r)\n",
      "            discount=discount*self.delta\n",
      "            \n",
      "        return v_pol\n",
      "    \n",
      "    def greedy(self,w):\n",
      "        w=np.array(w)\n",
      "        objf=self.r+self.delta*self.Q.dot(w)\n",
      "        policy=np.argmax(objf, axis=1)\n",
      "        return policy\n",
      "    \n",
      "    def policy_iteration(self,policy0,max_iter):\n",
      "        \n",
      "        policy_current=np.array(policy0)\n",
      "        for t in range(max_iter+1):\n",
      "            policy_next=self.greedy(self.value_of_policy(policy_current))\n",
      "            e=policy_next-policy_current\n",
      "            if e==np.zeros((self.n)):\n",
      "                break\n",
      "            policy_current=policy_next\n",
      "        return policy_current    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Apply this method to Kurtz' optimal decision(under construction)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kurtzsigma = MDP_pol_iter(r, delta, Q)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "policy_iter=P = kurtzsigma.policy_iteration(np.zeros(B+M+1),max_iter=10000)\n",
      "\n",
      "print(policy_iter)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "operands could not be broadcast together with shapes (16,6) (16,6,6) ",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-71-35f0d75806cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpolicy_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkurtzsigma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-69-1ab6d1104c5e>\u001b[0m in \u001b[0;36mpolicy_iteration\u001b[1;34m(self, policy0, max_iter)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mpolicy_current\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mpolicy_next\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgreedy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_of_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy_current\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0me\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpolicy_next\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpolicy_current\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-69-1ab6d1104c5e>\u001b[0m in \u001b[0;36mgreedy\u001b[1;34m(self, w)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgreedy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mobjf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mpolicy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (16,6) (16,6,6) "
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}